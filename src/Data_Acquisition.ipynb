{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "The goal of this assignment is to construct, analyze, and publish a dataset of monthly article traffic for a select set of pages from English Wikipedia from July 1, 2015 through September 30, 2023. Your notebook(s) and your data files will be uploaded to a repository of your choosing. You will submit a  link to your repository to enable grading of this assignment. The purpose of the assignment is to develop and follow best practices for open scientific research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Acquisition\n",
    "In order to measure article traffic from 2015-2023, you will need to collect data from the Pageviews API. The Pageviews API (documentation, endpoint) provides access to desktop, mobile web, and mobile app traffic data from July 2015 through the previous complete month.\n",
    "\n",
    "To get you started, you can refer to this example notebook that contains sample code to make the Pageviews Wikipedia API call. This sample code is licensed CC-BY, please feel free to reuse any of the code in the example notebook with appropriate attribution.\n",
    "\n",
    "You will be collecting counts of pageviews using a specified subset of Wikipedia article pages. This is a subset of the English Wikipedia that represents a large number of articles about academy award winning movies.\n",
    "You will use the same article subset to create several related data sets. All of the data sets are time series of monthly activity. For all of the data sets we are only interested in actual user pageview requests. The three resulting datasets should be saved as JSON files ordered using article titles as a key for the resulting time series data. You should store the time series data as returned from the API, with the exception of removing the ‘access’ field as it is misleading for mobile and cumulative files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.i. Importing the required libraries\n",
    "- We start by importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time, urllib.parse\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.ii. Configuring the API parameters\n",
    "### License\n",
    "This code example was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - August 14, 2023\n",
    "\n",
    "- We read the cleaned .csv file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"..\",\"data\",\"thank_the_academy.AUG.2023.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests\n",
    "API_REQUEST_PAGEVIEWS_ENDPOINT = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'\n",
    "\n",
    "# This is a parameterized string that specifies what kind of pageviews request we are going to make\n",
    "# In this case it will be a 'per-article' based request. The string is a format string so that we can\n",
    "# replace each parameter with an appropriate value before making the request\n",
    "API_REQUEST_PER_ARTICLE_PARAMS = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'\n",
    "\n",
    "# The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making a request to the Wikimedia API they ask that you include a \"unique ID\" that will allow them to\n",
    "# contact you if something happens - such as - your code exceeding request limits - or some other error happens\n",
    "\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<sagnik99@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# The name of the academy movie from the input file is saved as a list of Article Titles\n",
    "ARTICLE_TITLES = df['name']\n",
    "\n",
    "# This template is used to map parameter values into the API_REQUST_PER_ARTICLE_PARAMS portion of an API request. The dictionary has a\n",
    "# field/key for each of the required parameters. In the example, below, we only vary the article name, so the majority of the fields\n",
    "# can stay constant for each request. Of course, these values *could* be changed if necessary.\n",
    "ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"desktop\",      # this will be changed for different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015070100\",   # For this examples the start date is July 2015\n",
    "    \"end\":         \"2023093000\"    # For this example the end date is Sept 2023\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The API request will be made using one procedure. The idea is to make this reusable. The procedure is parameterized, but relies on the constants above for the important parameters. The underlying assumption is that this will be used to request data for a set of article pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_pageviews_per_article(article_title = None, \n",
    "                                  endpoint_url = API_REQUEST_PAGEVIEWS_ENDPOINT, \n",
    "                                  endpoint_params = API_REQUEST_PER_ARTICLE_PARAMS, \n",
    "                                  request_template = ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE,\n",
    "                                  headers = REQUEST_HEADERS):\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['article'] = article_title\n",
    "\n",
    "    if not request_template['article']:\n",
    "        raise Exception(\"Must supply an article title to make a pageviews request.\")\n",
    "    \n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(request_template['article'].replace(' ','_'))\n",
    "    request_template['article'] = article_title_encoded\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.iii. Extracting data from Wikipedia\n",
    "- The below code runs through various access types and fetches data for all the given article titles. We have added a try & except block to ensure the code does not break due to a failure or latency at the server end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1359/1359 [15:20<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "access_type = ['mobile-app', 'mobile-web', 'desktop', 'all-access']\n",
    "views_list = []\n",
    "for i in tqdm(range(len(ARTICLE_TITLES))):\n",
    "    try: \n",
    "        for j in access_type:\n",
    "            ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE['access'] = j\n",
    "            views = request_pageviews_per_article(ARTICLE_TITLES[i])\n",
    "            views_list.append(pd.json_normalize(views['items']))\n",
    "    except:\n",
    "        print(\"Could not get data for: \",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the list into a dataframe for easier data manipulation\n",
    "df_views = pd.concat(views_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.iv. Creating JSON files for each access type\n",
    "\n",
    "1. **Monthly mobile access** - The API separates mobile access types into two separate requests, you will need to sum these to make one count for all mobile pageviews. You should store the mobile access data in a file called:\n",
    "academy_monthly_mobile_&lt;startYYYYMM&gt;-&lt;endYYYYMM&gt;.json\n",
    "\n",
    "2. **Monthly desktop access** - Monthly desktop page traffic is based on one single request. You should store the desktop access data in a file called:\n",
    "academy_monthly_desktop_&lt;startYYYYMM&gt;-&lt;endYYYYMM&gt;.json\n",
    "\n",
    "3. **Monthly cumulative** - Monthly cumulative data is the sum of all mobile, and all desktop traffic per article. You should store the monthly cumulative data in a file called:\n",
    "academy_monthly_cumulative_&lt;startYYYYMM&gt;-&lt;endYYYYMM&gt;.json\n",
    "\n",
    "For all of the files the &lt;startYYYYMM&gt; and &lt;endYYYYMM&gt; represent the starting and ending year and month as integer text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>article</th>\n",
       "      <th>granularity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>access</th>\n",
       "      <th>agent</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Everything_Everywhere_All_at_Once</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2020010100</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>user</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Everything_Everywhere_All_at_Once</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2020020100</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>user</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Everything_Everywhere_All_at_Once</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2020030100</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>user</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Everything_Everywhere_All_at_Once</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2020040100</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>user</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Everything_Everywhere_All_at_Once</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2020050100</td>\n",
       "      <td>mobile-app</td>\n",
       "      <td>user</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Zorba_the_Greek_(film)</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2023050100</td>\n",
       "      <td>all-access</td>\n",
       "      <td>user</td>\n",
       "      <td>13025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Zorba_the_Greek_(film)</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2023060100</td>\n",
       "      <td>all-access</td>\n",
       "      <td>user</td>\n",
       "      <td>12631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Zorba_the_Greek_(film)</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2023070100</td>\n",
       "      <td>all-access</td>\n",
       "      <td>user</td>\n",
       "      <td>20739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Zorba_the_Greek_(film)</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2023080100</td>\n",
       "      <td>all-access</td>\n",
       "      <td>user</td>\n",
       "      <td>19522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>en.wikipedia</td>\n",
       "      <td>Zorba_the_Greek_(film)</td>\n",
       "      <td>monthly</td>\n",
       "      <td>2023090100</td>\n",
       "      <td>all-access</td>\n",
       "      <td>user</td>\n",
       "      <td>18216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515836 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         project                            article granularity   timestamp  \\\n",
       "0   en.wikipedia  Everything_Everywhere_All_at_Once     monthly  2020010100   \n",
       "1   en.wikipedia  Everything_Everywhere_All_at_Once     monthly  2020020100   \n",
       "2   en.wikipedia  Everything_Everywhere_All_at_Once     monthly  2020030100   \n",
       "3   en.wikipedia  Everything_Everywhere_All_at_Once     monthly  2020040100   \n",
       "4   en.wikipedia  Everything_Everywhere_All_at_Once     monthly  2020050100   \n",
       "..           ...                                ...         ...         ...   \n",
       "94  en.wikipedia             Zorba_the_Greek_(film)     monthly  2023050100   \n",
       "95  en.wikipedia             Zorba_the_Greek_(film)     monthly  2023060100   \n",
       "96  en.wikipedia             Zorba_the_Greek_(film)     monthly  2023070100   \n",
       "97  en.wikipedia             Zorba_the_Greek_(film)     monthly  2023080100   \n",
       "98  en.wikipedia             Zorba_the_Greek_(film)     monthly  2023090100   \n",
       "\n",
       "        access agent  views  \n",
       "0   mobile-app  user     65  \n",
       "1   mobile-app  user    152  \n",
       "2   mobile-app  user    120  \n",
       "3   mobile-app  user    284  \n",
       "4   mobile-app  user    231  \n",
       "..         ...   ...    ...  \n",
       "94  all-access  user  13025  \n",
       "95  all-access  user  12631  \n",
       "96  all-access  user  20739  \n",
       "97  all-access  user  19522  \n",
       "98  all-access  user  18216  \n",
       "\n",
       "[515836 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We create a function to perform the required operations and writing it into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_json(df, access_type):\n",
    "    if access_type == 'cumulative':\n",
    "        cols = df.columns.to_list()\n",
    "        cols.remove('views')\n",
    "        df = df.groupby(cols).sum().groupby('article').cumsum().reset_index()\n",
    "\n",
    "    if access_type == 'mobile':\n",
    "        cols = df.columns.to_list()\n",
    "        cols.remove('views')\n",
    "        df = df.groupby(cols).agg({'views' : np.sum}).reset_index()\n",
    "\n",
    "    df = df.sort_values(by=['article', 'timestamp'], ascending=True)\n",
    "    output = df.to_json(orient='records')[1:-1].replace('},{', '} {')\n",
    "    output = '['+output+']'\n",
    "    output = re.sub(\"}\\s{\", \"},{\", output)\n",
    "    parsed = json.loads(output)\n",
    "    json_object = json.dumps(parsed, indent=4)\n",
    "\n",
    "    data_folder = \"data\"\n",
    "    filename = f\"academy_monthly_{access_type}_201507-202309.json\"\n",
    "    path = os.path.join(\"..\", data_folder, filename)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(json_object)\n",
    "    print(\"Done for: \", access_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_json(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    write_to_json(df[df['access']=='desktop'].drop(['access','index'], axis = 1), 'desktop')\n",
    "    write_to_json(df[(df['access']=='mobile-app') | (df['access'] == 'mobile-web')].drop(['access','index'], axis = 1), 'mobile')\n",
    "    write_to_json(df[df['access']=='all-access'].drop(['access','index'], axis = 1), 'cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for:  desktop\n",
      "Done for:  mobile\n",
      "Done for:  cumulative\n"
     ]
    }
   ],
   "source": [
    "# Calling the function and passing the dataframe which contains the data as dumped by the API call.\n",
    "output_json(df_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please execute the Data_Analysis.ipynb file after this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
